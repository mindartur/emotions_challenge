{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "\n",
    "COMPOSED_TABLES_DIR = 'transformed_data_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b023e19b97743189b26fabf22d73d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=312), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# count the labels distribution and distribution of labels in files\n",
    "# uses files from data_omposer.py\n",
    "\n",
    "def get_data():\n",
    "    labels_count = defaultdict(int)\n",
    "    labels_files = {}\n",
    "    \n",
    "    for file_name in tqdm(os.listdir(COMPOSED_TABLES_DIR)):\n",
    "        df = pd.read_csv(os.path.join(COMPOSED_TABLES_DIR, file_name), delimiter=',', usecols=['Anger','Sad','Disgust','Happy','Scared','Neutral'])\n",
    "        # X = df.iloc[:, 10:].as_matrix()\n",
    "        # agreement = df['Agreement score']\n",
    "        sum_y = df.sum(axis=0)\n",
    "        local_count = dict()\n",
    "        for i, elem in enumerate(sum_y):\n",
    "            labels_count[i] += elem\n",
    "            local_count[i] = elem\n",
    "        labels_files[file_name] = local_count\n",
    "    return labels_files, labels_count\n",
    "    \n",
    "labels_files, labels_count = get_data()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_distribution = defaultdict(list)\n",
    "for filename, value in labels_files.items():\n",
    "    files_distribution[max(value, key=(lambda key: value[key]))].append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1}\n",
      "{0: 5, 1: 5, 2: 5, 3: 5, 4: 5, 5: 5}\n",
      "total test files amount:  6\n"
     ]
    }
   ],
   "source": [
    "min_label_amount = labels_count[min(labels_count, key=lambda x: labels_count[x])]\n",
    "# test_count = {key:int(1 *labels_count[key]/min_label_amount) for key in labels_count}\n",
    "test_count = {key:int(1) for key in labels_count}\n",
    "train_count = {key:int(5) for key in labels_count}\n",
    "\n",
    "print(test_count)\n",
    "print(train_count)\n",
    "print('total test files amount: ', sum(test_count.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['idac6a0586.csv', 'idc8354906.csv', 'idf948893b.csv', 'idf71db6d3.csv', 'id6d07cec0.csv', 'id37146566.csv']\n",
      "['id30df640d.csv', 'ide3e0992e.csv', 'idc057e450.csv', 'idd721711a.csv', 'id460cb4e1.csv', 'idf827ecb9.csv', 'id19a15835.csv', 'idc9080807.csv', 'id8ea05146.csv', 'id77720abd.csv', 'id389f85a6.csv', 'id59bdd597.csv', 'id7d0837f1.csv', 'id8ecc3ed4.csv', 'id8036ccb4.csv', 'id8e07f9e9.csv', 'ide39e7915.csv', 'id23c83985.csv', 'id41dbbc2f.csv', 'id3e9214e0.csv', 'id3823bead.csv', 'idfe60d720.csv', 'idfc9eb423.csv', 'id6608bab6.csv', 'id1d656472.csv', 'id8fb90973.csv', 'id2ffb83a8.csv', 'ide7ff1648.csv', 'idd7aeecb6.csv', 'id9ee0e61f.csv']\n",
      "6 30\n"
     ]
    }
   ],
   "source": [
    "to_test = []\n",
    "for key in test_count:\n",
    "    to_test += random.sample(files_distribution[key], test_count[key])\n",
    "\n",
    "to_train = []\n",
    "for key in train_count:\n",
    "    to_train += random.sample(files_distribution[key], train_count[key])\n",
    "\n",
    "print(to_test)\n",
    "print(to_train)\n",
    "print(len(to_test), len(to_train))\n",
    "# let's use this subset of files as a test and train subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('test_subset.pkl', 'wb') as f:\n",
    "    pickle.dump(to_test, f)\n",
    "with open('train_subset.pkl', 'wb') as f:\n",
    "    pickle.dump(to_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
