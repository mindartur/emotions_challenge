{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "try:\n",
    "    from keras.layers import CuDNNLSTM as LSTM\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    from keras.layers import LSTM\n",
    "from keras import regularizers\n",
    "from keras.layers import Bidirectional\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.layers import TimeDistributed\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import h5py \n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "logger = logging.getLogger('data.composer')\n",
    "\n",
    "COMPOSED_TABLES_DIR = 'transformed_data_1'\n",
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOK_BACK = 100\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "all_files = set(os.listdir(COMPOSED_TABLES_DIR))\n",
    "with open('test_subset.pkl', 'rb') as f:\n",
    "    test_files = set(pickle.load(f))\n",
    "with open('train_subset.pkl', 'rb') as f:\n",
    "    train_files = set(pickle.load(f))\n",
    "# train_files = all_files.difference(test_files)\n",
    "\n",
    "def get_data(files):\n",
    "    for file_name in files:\n",
    "        # logger.info(file_name)\n",
    "        print(os.path.join(COMPOSED_TABLES_DIR, file_name))\n",
    "        df = pd.read_csv(os.path.join(COMPOSED_TABLES_DIR, file_name), delimiter=',')\n",
    "        X = df.iloc[:, 10:].as_matrix()\n",
    "        y = df[['Anger','Sad','Disgust','Happy','Scared','Neutral']].as_matrix()\n",
    "        agreement = df['Agreement score']\n",
    "        X = scaler.fit_transform(X)\n",
    "        Xd, yd = create_dataset(X, y, agreement, LOOK_BACK)\n",
    "        yield Xd, yd\n",
    "\n",
    "def get_test_data():\n",
    "    iterator = get_data(test_files)\n",
    "    for X, y in iterator:\n",
    "        # y = y.reshape((y.shape[0] * y.shape[1], 6))\n",
    "        for i in range(0, len(X)-101, 100):\n",
    "            yield X[i:i+100], y[i:i+100]\n",
    "        yield X[i:], y[i:]\n",
    "        # yield X, y\n",
    "        \n",
    "def create_dataset(X, y, agreement, look_back=100):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(0, len(X)-look_back-1, 1):\n",
    "        dataX.append(X[i:i+look_back])\n",
    "        y_mul_agr = y[i:i+look_back]\n",
    "        dataY.append(np.average(y_mul_agr, axis=0))\n",
    "        # dataY.append(y_mul_agr)\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "    \n",
    "def create_model():\n",
    "#     model.add(TimeDistributed(Dense(100, kernel_regularizer=regularizers.l2(0.01),\n",
    "#                 activity_regularizer=regularizers.l1(0.01), kernel_initializer='he_uniform'), input_shape=(LOOK_BACK, 177)))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(TimeDistributed(Dense(100, kernel_regularizer=regularizers.l2(0.01),\n",
    "#                 activity_regularizer=regularizers.l1(0.01), kernel_initializer='he_uniform')))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(LOOK_BACK, 177)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
    "    model.add(Dropout(0.3))\n",
    "#     model.add(TimeDistributed(Dense(100, kernel_regularizer=regularizers.l2(0.01),\n",
    "#                 activity_regularizer=regularizers.l1(0.01), kernel_initializer='he_uniform')))\n",
    "#     model.add(TimeDistributed(Dense(100, kernel_regularizer=regularizers.l2(0.01),\n",
    "#                 activity_regularizer=regularizers.l1(0.01), kernel_initializer='he_uniform')))\n",
    "#     model.add(TimeDistributed(Dense(50, kernel_regularizer=regularizers.l2(0.01),\n",
    "#                 activity_regularizer=regularizers.l1(0.01), kernel_initializer='he_uniform')))\n",
    "    model.add(Dense(200, activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(6, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l2(0.01), kernel_initializer='he_uniform'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "def train():\n",
    "    for file_num, (trainX, trainY) in enumerate(get_data(train_files)):\n",
    "        print(file_num, '/', len(train_files))\n",
    "        print('Y: ', np.average(trainY, axis=0))\n",
    "\n",
    "        model.fit(trainX, trainY, epochs=1, batch_size=64, verbose=1)\n",
    "\n",
    "    model.save('lstm_keras.h5')\n",
    "    return model\n",
    "\n",
    "def invert_categorical(arr):\n",
    "    labels = []\n",
    "    for row in arr:\n",
    "        labels.append(np.argmax(row))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed_data_1\\idfc9eb423.csv\n",
      "0 / 30\n",
      "Y:  [ 0.00344788  0.          0.          0.          0.99655212  0.        ]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 22s 5ms/step - loss: 31.5554 - acc: 0.6575\n",
      "transformed_data_1\\id7d0837f1.csv\n",
      "1 / 30\n",
      "Y:  [ 0.          0.          0.88518691  0.          0.          0.11481309]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 14.4665 - acc: 0.0019\n",
      "transformed_data_1\\id460cb4e1.csv\n",
      "2 / 30\n",
      "Y:  [ 1.  0.  0.  0.  0.  0.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 14.1171 - acc: 0.0058\n",
      "transformed_data_1\\idc057e450.csv\n",
      "3 / 30\n",
      "Y:  [ 1.  0.  0.  0.  0.  0.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 13.6741 - acc: 0.8440\n",
      "transformed_data_1\\id77720abd.csv\n",
      "4 / 30\n",
      "Y:  [ 0.          0.69333488  0.          0.          0.          0.30666512]\n",
      "Epoch 1/1\n",
      "4306/4306 [==============================] - 16s 4ms/step - loss: 13.4206 - acc: 0.0000e+00\n",
      "transformed_data_1\\id19a15835.csv\n",
      "5 / 30\n",
      "Y:  [ 0.  1.  0.  0.  0.  0.]\n",
      "Epoch 1/1\n",
      "4306/4306 [==============================] - 16s 4ms/step - loss: 12.9491 - acc: 0.0434\n",
      "transformed_data_1\\id1d656472.csv\n",
      "6 / 30\n",
      "Y:  [ 0.22398978  0.35891779  0.          0.          0.41709243  0.        ]\n",
      "Epoch 1/1\n",
      "4306/4306 [==============================] - 16s 4ms/step - loss: 12.5774 - acc: 0.3435\n",
      "transformed_data_1\\id8036ccb4.csv\n",
      "7 / 30\n",
      "Y:  [ 0.  0.  1.  0.  0.  0.]\n",
      "Epoch 1/1\n",
      "4306/4306 [==============================] - 16s 4ms/step - loss: 12.3349 - acc: 0.0000e+00\n",
      "transformed_data_1\\idd721711a.csv\n",
      "8 / 30\n",
      "Y:  [ 1.  0.  0.  0.  0.  0.]\n",
      "Epoch 1/1\n",
      "4308/4308 [==============================] - 16s 4ms/step - loss: 11.8127 - acc: 0.6799\n",
      "transformed_data_1\\ide7ff1648.csv\n",
      "9 / 30\n",
      "Y:  [ 0.  0.  0.  0.  0.  1.]\n",
      "Epoch 1/1\n",
      "4306/4306 [==============================] - 16s 4ms/step - loss: 11.7698 - acc: 0.0000e+00\n",
      "transformed_data_1\\id23c83985.csv\n",
      "10 / 30\n",
      "Y:  [ 0.  0.  0.  1.  0.  0.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 11.4512 - acc: 0.0000e+00\n",
      "transformed_data_1\\id41dbbc2f.csv\n",
      "11 / 30\n",
      "Y:  [ 0.  0.  0.  1.  0.  0.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 10.9947 - acc: 0.0000e+00\n",
      "transformed_data_1\\id389f85a6.csv\n",
      "12 / 30\n",
      "Y:  [ 0.  0.  1.  0.  0.  0.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 10.6308 - acc: 0.0562\n",
      "transformed_data_1\\id8fb90973.csv\n",
      "13 / 30\n",
      "Y:  [ 0.  0.  0.  0.  0.  1.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 10.3767 - acc: 0.0000e+00\n",
      "transformed_data_1\\idf827ecb9.csv\n",
      "14 / 30\n",
      "Y:  [ 0.  1.  0.  0.  0.  0.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 10.0486 - acc: 0.0894\n",
      "transformed_data_1\\id8ea05146.csv\n",
      "15 / 30\n",
      "Y:  [ 0.  1.  0.  0.  0.  0.]\n",
      "Epoch 1/1\n",
      "4306/4306 [==============================] - 16s 4ms/step - loss: 9.6071 - acc: 0.9401\n",
      "transformed_data_1\\idc9080807.csv\n",
      "16 / 30\n",
      "Y:  [ 0.  1.  0.  0.  0.  0.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 9.1779 - acc: 1.0000\n",
      "transformed_data_1\\id30df640d.csv\n",
      "17 / 30\n",
      "Y:  [ 1.  0.  0.  0.  0.  0.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 9.1946 - acc: 0.0000e+00\n",
      "transformed_data_1\\idd7aeecb6.csv\n",
      "18 / 30\n",
      "Y:  [ 0.  0.  0.  0.  0.  1.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 8.9322 - acc: 0.0000e+00\n",
      "transformed_data_1\\id9ee0e61f.csv\n",
      "19 / 30\n",
      "Y:  [ 0.  0.  0.  0.  0.  1.]\n",
      "Epoch 1/1\n",
      "4306/4306 [==============================] - 16s 4ms/step - loss: 8.5275 - acc: 0.0423\n",
      "transformed_data_1\\id3e9214e0.csv\n",
      "20 / 30\n",
      "Y:  [ 0.  0.  0.  1.  0.  0.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 8.4835 - acc: 0.0000e+00\n",
      "transformed_data_1\\id6608bab6.csv\n",
      "21 / 30\n",
      "Y:  [ 0.  0.  0.  0.  1.  0.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 8.4091 - acc: 0.0000e+00\n",
      "transformed_data_1\\id3823bead.csv\n",
      "22 / 30\n",
      "Y:  [ 0.37114  0.       0.       0.       0.62886  0.     ]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 7.9760 - acc: 0.0000e+00\n",
      "transformed_data_1\\ide39e7915.csv\n",
      "23 / 30\n",
      "Y:  [ 0.00610169  0.          0.          0.99389831  0.          0.        ]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 7.6389 - acc: 0.0093\n",
      "transformed_data_1\\idfe60d720.csv\n",
      "24 / 30\n",
      "Y:  [ 0.  0.  0.  0.  1.  0.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 7.4558 - acc: 0.0000e+00\n",
      "transformed_data_1\\id8e07f9e9.csv\n",
      "25 / 30\n",
      "Y:  [ 0.  0.  0.  1.  0.  0.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 7.0831 - acc: 0.9366\n",
      "transformed_data_1\\id8ecc3ed4.csv\n",
      "26 / 30\n",
      "Y:  [ 0.  0.  1.  0.  0.  0.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 7.1479 - acc: 0.0000e+00\n",
      "transformed_data_1\\id2ffb83a8.csv\n",
      "27 / 30\n",
      "Y:  [ 0.  0.  0.  0.  0.  1.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 6.7109 - acc: 0.0176\n",
      "transformed_data_1\\ide3e0992e.csv\n",
      "28 / 30\n",
      "Y:  [ 1.  0.  0.  0.  0.  0.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 6.6137 - acc: 0.0000e+00\n",
      "transformed_data_1\\id59bdd597.csv\n",
      "29 / 30\n",
      "Y:  [ 0.  0.  1.  0.  0.  0.]\n",
      "Epoch 1/1\n",
      "4307/4307 [==============================] - 16s 4ms/step - loss: 6.4185 - acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "create_model()\n",
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "transformed_data_1\\idac6a0586.csv\n",
      "transformed_data_1\\id37146566.csv\n",
      "transformed_data_1\\idc8354906.csv\n",
      "transformed_data_1\\id6d07cec0.csv\n",
      "transformed_data_1\\idf948893b.csv\n",
      "transformed_data_1\\idf71db6d3.csv\n",
      "(26440, 6) (26440, 6)\n",
      "26440 26440\n",
      "Accuracy:  0.166679273828\n",
      "Confusion matrix: \n",
      "[[   0    0    0    0    0 4406]\n",
      " [   0    0    0    0    0 4407]\n",
      " [   0    0    0    0    0 4407]\n",
      " [   0    0    0    0    0 4407]\n",
      " [   0    0    0    0    0 4406]\n",
      " [   0    0    0    0    0 4407]]\n"
     ]
    }
   ],
   "source": [
    "model = load_model('lstm_keras.h5')\n",
    "print('model loaded')\n",
    "\n",
    "generator = get_test_data()\n",
    "testX, testY = next(generator)\n",
    "predicted =  model.predict_on_batch(testX)\n",
    "for testX1, testY1 in generator:\n",
    "    testY = np.concatenate((testY, testY1), axis=0)\n",
    "    predicted1 = model.predict_on_batch(testX1)\n",
    "    predicted = np.concatenate((predicted, predicted1), axis=0)\n",
    "    \n",
    "print(testY.shape, predicted.shape)\n",
    "# testY = testY.reshape((testY.shape[0] * testY.shape[1], 6))\n",
    "# predicted = predicted.reshape((predicted.shape[0] * predicted.shape[1], 6))\n",
    "testY_labels = invert_categorical(testY)\n",
    "\n",
    "predicted_labels = invert_categorical(predicted)\n",
    "print(len(predicted), len(testY_labels))\n",
    "print('Accuracy: ', accuracy_score(testY_labels, predicted_labels))\n",
    "print('Confusion matrix: ')\n",
    "print(confusion_matrix(testY_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame([1.0, 2.0, 3.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "dtype: int32"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a == 0).all(axis=1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  1.0\n",
       "1  2.0\n",
       "2  3.0\n",
       "3  0.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
